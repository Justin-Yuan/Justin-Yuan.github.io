---
---

@article{ramakrishnan2025omnidraft,
  title={OmniDraft: A Cross-vocabulary, Online Adaptive Drafter for On-device Speculative Decoding},
  author={Ramakrishnan, Ramchalam Kinattinkara and Yuan, Zhaocong and Zhuo, Shaojie and Feng, Chen and Lin, Yicheng and Su, Chenzheng and Zhang, Xiaopeng},
  journal={arXiv preprint arXiv:2507.02659},
  year={2025},
  abbr={NeurIPS},
  abstract={Speculative decoding generally dictates having a small, efficient draft model that is either pretrained or distilled offline to a particular target model series, for instance, Llama or Qwen models. However, within online deployment settings, there are two major challenges: 1) usage of a target model that is incompatible with the draft model; 2) expectation of latency improvements over usage and time. In this work, we propose OmniDraft, a unified framework that enables a single draft model to operate with any target model and adapt dynamically to user data. We introduce an online n-gram cache with hybrid distillation fine-tuning to address the cross-vocabulary mismatch across draft and target models; and further improve decoding speed by leveraging adaptive drafting techniques. OmniDraft is particularly suitable for on-device LLM applications where model cost, efficiency and user customization are the major points of contention. This further highlights the need to tackle the above challenges and motivates the \textit{``one drafter for all''} paradigm. We showcase the proficiency of the OmniDraft framework by performing online learning on math reasoning, coding and text generation tasks. Notably, OmniDraft enables a single Llama-68M model to pair with various target models including Vicuna-7B, Qwen2-7B and Llama3-8B models for speculative decoding; and additionally provides up to 1.5-2x speedup.},
  pdf={https://arxiv.org/abs/2507.02659},
  selected={true}
}

@article{feng2025edge,
  title={Edge-ASR: Towards Low-Bit Quantization of Automatic Speech Recognition Models},
  author={Feng, Chen and Lin, Yicheng and Zhuo, Shaojie and Su, Chenzheng and Ramakrishnan, Ramchalam Kinattinkara and Yuan, Zhaocong and Zhang, Xiaopeng},
  journal={arXiv preprint arXiv:2507.07877},
  year={2025},
  abbr={arXiv},
  abstract={Recent advances in Automatic Speech Recognition (ASR) have demonstrated remarkable accuracy and robustness in diverse audio applications, such as live transcription and voice command processing. However, deploying these models on resource-constrained edge devices (e.g., IoT device, wearables) still presents substantial challenges due to strict limits on memory, compute and power. Quantization, particularly Post-Training Quantization (PTQ), offers an effective way to reduce model size and inference cost without retraining. Despite its importance, the performance implications of various advanced quantization methods and bit-width configurations on ASR models remain unclear. In this work, we present a comprehensive benchmark of eight state-of-the-art (SOTA) PTQ methods applied to two leading edge-ASR model families, Whisper and Moonshine. We systematically evaluate model performances (i.e., accuracy, memory I/O and bit operations) across seven diverse datasets from the open ASR leader-board, analyzing the impact of quantization and various configurations on both weights and activations. Built on an extension of the LLM compression toolkit, our framework integrates edge-ASR models, diverse advanced quantization algorithms, a unified calibration and evaluation data pipeline, with detailed analysis tools. Our results characterize the trade-offs between efficiency and accuracy, demonstrating that even 3-bit quantization can succeed on high capacity models when using advanced PTQ techniques. These findings provide valuable insights for optimizing ASR models on low-power, always-on edge devices.},
  pdf={https://arxiv.org/abs/2507.07877},
  selected={true}
}

@article{feng2024stepping,
  title={Stepping forward on the last mile},
  author={Feng, Chen and Zhuo, Jay and Zhang, Parker and Kinattinkara Ramakrishnan, Ramchalam and Yuan, Zhaocong and Li, Andrew Zou},
  journal={Advances in Neural Information Processing Systems},
  volume={37},
  pages={94851--94870},
  year={2024},
  abbr={NeurIPS},
  abstract={Continuously adapting pre-trained models to local data on resource constrained edge devices is the $\emph{last mile}$ for model deployment. However, as models increase in size and depth, backpropagation requires a large amount of memory, which becomes prohibitive for edge devices. In addition, most existing low power neural processing engines (e.g., NPUs, DSPs, MCUs, etc.) are designed as fixed-point inference accelerators, without training capabilities. Forward gradients, solely based on directional derivatives computed from two forward calls, have been recently used for model training, with substantial savings in computation and memory. However, the performance of quantized training with fixed-point forward gradients remains unclear. In this paper, we investigate the feasibility of on-device training using fixed-point forward gradients, by conducting comprehensive experiments across a variety of deep learning benchmark tasks in both vision and audio domains. We propose a series of algorithm enhancements that further reduce the memory footprint, and the accuracy gap compared to backpropagation. An empirical study on how training with forward gradients navigates in the loss landscape is further explored. Our results demonstrate that on the last mile of model customization on edge devices, training with fixed-point forward gradients is a feasible and practical approach.},
  pdf={https://arxiv.org/abs/2411.04036},
  selected={true}
}

@inproceedings{glossop2022characterising,
  title={Characterising the Robustness of Reinforcement Learning for Continuous Control using Disturbance Injection},
  author={Catherine Glossop and Jacopo Panerati and Amrit Krishnan and Zhaocong Yuan and Angela P. Schoellig},
  booktitle={NeurIPS 2022 Workshop on Distribution Shifts: Connecting Methods and Applications},
  year={2022},
  url={https://openreview.net/forum?id=dJPzobZtpZ},
  abbr={NeurIPS Workshop},
  abstract={In this study, we leverage the deliberate and systematic fault-injection capabilities of an open-source benchmark suite to perform a series of experiments on state-of-the-art deep and robust reinforcement learning algorithms. We aim to benchmark robustness in the context of continuous action spaces -- crucial for deployment in robot control. We find that robustness is more prominent for action disturbances than it is for disturbances to observations and dynamics. We also observe that state-of-the-art approaches that are not explicitly designed to improve robustness perform at a level comparable to that achieved by those that are. Our study and results are intended to provide insight into the current state of safe and robust reinforcement learning and a foundation for the advancement of the field, in particular, for deployment in robotic systems.},
  pdf={https://openreview.net/forum?id=dJPzobZtpZ},
  blog={https://vectorinstitute.ai/vector-ai-engineering-blog-benchmarking-robustness-of-reinforcement-learning-approaches-using-safe-control-gym/}
}

@mastersthesis{yuan2022benchmarking,
  title={Benchmarking Reinforcement Learning for Safe Robotics: Constraints, Robustness and Transfer},
  author={Zhaocong Yuan},
  year={2022},
  school={University of Toronto},
  abbr={Thesis},
  abstract={Safe learning in robotics aims to deploy robots in real life with complex tasks and safety requirements. To push the agenda of safe learning, a crucial step is establishing common benchmarks that facilitate both reliable evaluations and research development. In this work, we contribute towards this goal by surveying the safe learning literature and proposing a versatile safe learning benchmark suite, safe-control-gym. The benchmark implements a variety of safe learning algorithms spanning control to reinforcement learning, it also implements critical features to support safety-relevant evaluations and algorithm development. With safe-control-gym, we conduct careful benchmarking on model-free reinforcement learning methods with respect to three metrics of safety: constraint satisfaction, robustness, and transfer performance. We envision safe-control-gym to provide a framework that brings various research together, and most importantly to accelerate the progress of safe learning in robotics.},
  pdf={https://tspace.library.utoronto.ca/handle/1807/125223},
  code={https://github.com/Justin-Yuan/dsl__projects__benchmark/tree/benchmark}
}

@article{yuan2022safe,
  title={safe-Control-Gym: A Unified Benchmark Suite for Safe Learning-Based Control and Reinforcement Learning in Robotics},
  author={Yuan, Zhaocong and Hall, Adam W and Zhou, Siqi and Brunke, Lukas and Greeff, Melissa and Panerati, Jacopo and Schoellig, Angela P},
  journal={IEEE Robotics and Automation Letters},
  year={2022},
  publisher={IEEE},
  abbr={IROS},
  abstract={In recent years, both reinforcement learning and learning-based control—as well as the study of their safety, which is crucial for deployment in real-world robots—have gained significant traction. However, to adequately gauge the progress and applicability of new results, we need the tools to equitably compare the approaches proposed by the controls and reinforcement learning communities. Here, we propose a new open-source benchmark suite, called safe-control-gym, supporting both model-based and databased control techniques. We provide implementations for three dynamic systems—the cart-pole, the 1D, and 2D quadrotor— and two control tasks—stabilization and trajectory tracking. We propose to extend OpenAI’s Gym API—the de facto standard in reinforcement learning research—with (i) the ability to specify (and query) symbolic dynamics and (ii) constraints, and (iii) (repeatably) inject simulated disturbances in the control inputs, state measurements, and inertial properties. To demonstrate our proposal and in an attempt to bring research communities closer together, we show how to use safe-control-gym to quantitatively compare the control performance, data efficiency, and safety of multiple approaches from the fields of traditional control, learning-based control, and reinforcement learning.},
  pdf={https://arxiv.org/abs/2109.06325},
  code={https://github.com/utiasDSL/safe-control-gym/tree/main},
  selected={true}
}

@article{brunke2022safe,
  title={Safe learning in robotics: From learning-based control to safe reinforcement learning},
  author={Brunke, Lukas and Greeff, Melissa and Hall, Adam W and Yuan, Zhaocong and Zhou, Siqi and Panerati, Jacopo and Schoellig, Angela P},
  journal={Annual Review of Control, Robotics, and Autonomous Systems},
  volume={5},
  pages={411--444},
  year={2022},
  publisher={Annual Reviews},
  abbr={Annual Reviews},
  abstract={The last half decade has seen a steep rise in the number of contributions on safe learning methods for real-world robotic deployments from both the control and reinforcement learning communities. This article provides a concise but holistic review of the recent advances made in using machine learning to achieve safe decision-making under uncertainties, with a focus on unifying the language and frameworks used in control theory and reinforcement learning research. It includes learning-based control approaches that safely improve performance by learning the uncertain dynamics, reinforcement learning approaches that encourage safety or robustness, and methods that can formally certify the safety of a learned control policy. As data- and learning-based robot control methods continue to gain traction, researchers must understand when and how to best leverage them in real-world scenarios where safety is imperative, such as when operating in close proximityto humans. We highlight some of the open challenges that will drive the field of robot learning in the coming years, and emphasize the need for realistic physics-based benchmarks to facilitate fair comparisons between control and reinforcement learning approaches.},
  pdf={https://www.annualreviews.org/content/journals/10.1146/annurev-control-042920-020211},
  code={https://github.com/utiasDSL/safe-control-gym/tree/ar},
  selected={true}
}

@thesis{yuan2020multi,
  title={Emergent Communication Behaviors in Multi-Agent Systems},
  author={Zhaocong Yuan},
  year={2020},
  school={University of Toronto},
  abbr={Thesis},
  abstract={Multi-agent systems are prevalent in real life, powering the majority of people's everyday activities. Multi-agent Reinforcement Learning is the study of these systems by means of machine learning, it has gained much attention in successfully applying to games, robotics and language understanding. This work concerns the emeregent behavior aspeect of MARL, speecifically emergent communications. We extend the MADDPG framework and experiment on a variety of multi-agent tasks from the eOpenAI Multi-agent Particle Environments, which span different behavior modes including cooperationo, competitiono, communication and mixture of those. Besides demonstrating the emergent behavior learnt from each task, we further provide analysis and insights regarding the MARL model design and training. At the end, we outline several possible lines for future work, hoping to inspire more multi-agent related research and advance the field of MARL.},
  pdf={https://tspace.library.utoronto.ca/handle/1807/125223},
  code={https://github.com/Justin-Yuan/learn-to-interact}
}

@inproceedings{kar2019meta,
  title={Meta-sim: Learning to generate synthetic datasets},
  author={Kar, Amlan and Prakash, Aayush and Liu, Ming-Yu and Cameracci, Eric and Yuan, Justin and Rusiniak, Matt and Acuna, David and Torralba, Antonio and Fidler, Sanja},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={4551--4560},
  year={2019},
  abbr={ICCV},
  abstract={Training models to high-end performance requires availability of large labeled datasets, which are expensive to get. The goal of our work is to automatically synthesize labeled datasets that are relevant for a downstream task. We propose Meta-Sim, which learns a generative model of synthetic scenes, and obtain images as well as its corresponding ground-truth via a graphics engine. We parametrize our dataset generator with a neural network, which learns to modify attributes of scene graphs obtained from probabilistic scene grammars, so as to minimize the distribution gap between its rendered outputs and target data. If the real dataset comes with a small labeled validation set, we additionally aim to optimize a meta-objective, i.e. downstream task performance. Experiments show that the proposed method can greatly improve content generation quality over a human-engineered probabilistic scene grammar, both qualitatively and quantitatively as measured by performance on a downstream task.},
  pdf={https://arxiv.org/abs/1904.11621},
  code={https://github.com/nv-tlabs/meta-sim},
  award={Oral},
  website={https://research.nvidia.com/labs/toronto-ai/meta-sim/},
  selected={true}
}